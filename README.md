# adversarial
adversial attacks: robutness of the classification
# Abstract

The advancements in data collection and computing power have led to use neural networks and
deep learning as solutions to solve complex problems. These methods seek to teach computers how
to perform tasks form experience and knowledge instead of explicitly programing them to perform a
task. Therefore, it is more important to ensure the security and robustness of the above-mentioned
algorithms. Recently, the security vulnerability of Deep learning algorithms to adversarial samples has
been extensively recognized as security concern for the reason that the fabricated samples can cause
numerous misbehaviors in the deep learning models while being seen as harmless by humans. This
paper demonstrates how we used adversarial training to enhance the robustness of our models. The
idea is we are going to use two adversarial attacks on the images in our dataset to cause deliberately
incorrect predictions or make the model unable to classify them correctly and then we will implement
methods to robust the neural network.
